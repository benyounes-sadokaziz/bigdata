# Flume configuration for consuming from Kafka and writing to HDFS

# Define the agent
agent2.sources = kafkaSource
agent2.sinks = hdfsSink
agent2.channels = memoryChannel

# Configure Kafka source
agent2.sources.kafkaSource.type = org.apache.flume.source.kafka.KafkaSource
agent2.sources.kafkaSource.kafka.bootstrap.servers = kafka:29092
agent2.sources.kafkaSource.kafka.topics = test-topic
agent2.sources.kafkaSource.kafka.consumer.group.id = flume-consumer-group
agent2.sources.kafkaSource.batchSize = 100
agent2.sources.kafkaSource.batchDurationMillis = 1000

# Configure HDFS sink
agent2.sinks.hdfsSink.type = hdfs
agent2.sinks.hdfsSink.hdfs.path = hdfs://namenode:9000/user/flume/kafka-data/%Y/%m/%d/%H
agent2.sinks.hdfsSink.hdfs.filePrefix = kafka-
agent2.sinks.hdfsSink.hdfs.fileSuffix = .log
agent2.sinks.hdfsSink.hdfs.rollInterval = 30
agent2.sinks.hdfsSink.hdfs.rollSize = 1048576
agent2.sinks.hdfsSink.hdfs.rollCount = 0
agent2.sinks.hdfsSink.hdfs.fileType = DataStream
agent2.sinks.hdfsSink.hdfs.writeFormat = Text
agent2.sinks.hdfsSink.hdfs.useLocalTimeStamp = true

# Configure memory channel
agent2.channels.memoryChannel.type = memory
agent2.channels.memoryChannel.capacity = 10000
agent2.channels.memoryChannel.transactionCapacity = 1000

# Bind the source and sink to the channel
agent2.sources.kafkaSource.channels = memoryChannel
agent2.sinks.hdfsSink.channel = memoryChannel
