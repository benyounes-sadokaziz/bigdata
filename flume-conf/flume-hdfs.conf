# Flume configuration for log file processing to HDFS

# Define the agent
agent1.sources = logSource
agent1.sinks = hdfsSink kafkaSink
agent1.channels = memoryChannel fileChannel

# Configure the source (Spooling Directory for log files)
agent1.sources.logSource.type = spooldir
agent1.sources.logSource.spoolDir = /logs/incoming
agent1.sources.logSource.fileHeader = true
agent1.sources.logSource.deletePolicy = immediate
agent1.sources.logSource.fileSuffix = .processed

# Configure HDFS sink
agent1.sinks.hdfsSink.type = hdfs
agent1.sinks.hdfsSink.hdfs.path = hdfs://namenode:9000/user/flume/logs/%Y/%m/%d
agent1.sinks.hdfsSink.hdfs.filePrefix = logs-
agent1.sinks.hdfsSink.hdfs.fileSuffix = .log
agent1.sinks.hdfsSink.hdfs.rollInterval = 60
agent1.sinks.hdfsSink.hdfs.rollSize = 1048576
agent1.sinks.hdfsSink.hdfs.rollCount = 100
agent1.sinks.hdfsSink.hdfs.fileType = DataStream
agent1.sinks.hdfsSink.hdfs.writeFormat = Text
agent1.sinks.hdfsSink.hdfs.useLocalTimeStamp = true

# Configure Kafka sink (optional - for real-time processing)
agent1.sinks.kafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.kafkaSink.kafka.bootstrap.servers = kafka:29092
agent1.sinks.kafkaSink.kafka.topic = flume-logs
agent1.sinks.kafkaSink.kafka.flumeBatchSize = 20
agent1.sinks.kafkaSink.kafka.producer.acks = 1

# Configure memory channel for HDFS
agent1.channels.memoryChannel.type = memory
agent1.channels.memoryChannel.capacity = 10000
agent1.channels.memoryChannel.transactionCapacity = 1000

# Configure file channel for Kafka (more reliable)
agent1.channels.fileChannel.type = file
agent1.channels.fileChannel.checkpointDir = /opt/flume/checkpoint
agent1.channels.fileChannel.dataDirs = /opt/flume/data

# Bind the source and sinks to the channels
agent1.sources.logSource.channels = memoryChannel fileChannel
agent1.sinks.hdfsSink.channel = memoryChannel
agent1.sinks.kafkaSink.channel = fileChannel
